{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# EEG Statistics\n",
    "\n",
    "## Epochs\n",
    "We need epochs for the statistical tests, so you can insert your preprocessed data from earlier tutorials under this section. I'll read in some epochs from your FaceWord which I prepared earlier and I'll be looking at the words/images contrast.\n",
    "\n",
    "(Tip: You can save the epochs object you created in your preprocessing notebook by using epochs.save('your_epochs-epo.fif'))\n",
    "\n",
    "(Extra tip: You can run terminal commands from cells using the os.system() function or simply writing an exclamation mark before the command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "!python -m pip install mne --quiet\n",
    "!pip install scikit-learn --quiet\n",
    "!pip install pandas --quiet\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Importing epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /work/studybuddies_neuroScience/own_experiment/ownExperiment_epochs-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     496.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "523 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "epochs = mne.read_epochs('ownExperiment_epochs-epo.fif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Dividing into different conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "incorr2_epocs = epochs['recog_phase/incorr2/second']\n",
    "incorr4_epocs = epochs['recog_phase/incorr2/second']\n",
    "corr5_epocs = epochs['recog_phase/corr/fifth']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Windowed mean\n",
    "Now we have our two conditions: trials with words vs images. One of the simplest way in which we can determine whether the signal in our two conditions are statistically significant is by:\n",
    "\n",
    "1) Segmenting our data using only certain channels in a specific time window. **Keep in mind which time window and channels should be established a priori, for instance according to the literature.** \n",
    "2) Taking the mean of that window across channels and and samples.\n",
    "3) Running statistical tests on the windowed means from the two conditions.\n",
    "\n",
    "In an experiment with multiple participants we would also average over trials from individual participants, in order to only have one data point per participant (and thereby avoid multiple comparisons). However, since we have one participant, we can keep one dimension of the individual data, i.e. the trials.\n",
    "\n",
    "### T-test\n",
    "We can now do a t-test on the trials from the two conditions, to establish whether the means of the two groups are statistically significant.\n",
    "\n",
    "We can use the get_data() function to get the numerical values of the signal (in microvolts) for the t-test. tmin and tmax are used to define the size of the window, and the picks are the channels that we expect to see an effect in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 3, 25)\n",
      "(25, 3, 25)\n",
      "(31, 3, 25)\n"
     ]
    }
   ],
   "source": [
    "incorr2_data = incorr2_epocs.get_data(picks=['O1', 'Oz', 'O2'], tmin=.1, tmax=.2) #01,Oz,02 centered around visCortex\n",
    "print(incorr2_data.shape)\n",
    "\n",
    "incorr4_data = incorr4_epocs.get_data(picks=['O1', 'Oz', 'O2'], tmin=.1, tmax=.2)\n",
    "print(incorr4_data.shape)\n",
    "\n",
    "corr5_data = corr5_epocs.get_data(picks=['O1', 'Oz', 'O2'], tmin=.1, tmax=.2)\n",
    "print(corr5_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "I've also tried adding \n",
    "```, 'P3', 'P4', 'Pz'``` \n",
    "to the electrodes (picks) without any luck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Investigating the resulting data; how many dimensions does the data have? What do you think they represent (i.e. which dimension is channels, trials, etc.)?\n",
    "\n",
    "Now we can average over the data so we only have the trials dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25,)\n",
      "(25,)\n",
      "(31,)\n"
     ]
    }
   ],
   "source": [
    "# Incorrect second\n",
    "incorr2_mean = np.mean(incorr2_data, axis=2) # averaging over the third dimension of the data\n",
    "incorr2_mean = np.mean(incorr2_mean, axis=1) # averaging over the second dimension of the data\n",
    "print(incorr2_mean.shape)\n",
    "\n",
    "# Incorrect fourth\n",
    "incorr4_mean = np.mean(incorr4_data, axis=2)\n",
    "incorr4_mean = np.mean(incorr4_mean, axis=1)\n",
    "print(incorr4_mean.shape)\n",
    "\n",
    "# Correct fifth\n",
    "corr5_mean = np.mean(corr5_data, axis=2)\n",
    "corr5_mean = np.mean(corr5_mean, axis=1)\n",
    "print(corr5_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=0.8060170719372484, pvalue=0.4237683846193888)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats as st\n",
    "import statistics as stats\n",
    "\n",
    "st.ttest_ind(a=incorr4_mean, b=corr5_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
